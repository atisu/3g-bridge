\documentclass[a4paper, 12pt]{article} 

\usepackage{t1enc} 
\usepackage[latin2]{inputenc} 
\usepackage{graphics} 
\usepackage{verbatim}

\title{Queue Manager User Manual -- v0.2}
% \resizebox{3cm}{!}{\includegraphics{sztaki.jpg}}
\author{Laboratory of Parallel and Distributed Systems}
\date{}

\begin{document} 
\pagestyle{empty}
\maketitle
\thispagestyle{empty}

\section{Queue Manager}

The purpose of the Queue Manager application is to create a connection between a submitter and a grid backend. The supported grid backends are BOINC and EGEE. The Queue Manager communicates with the submitter application via a MySQL database. The submitter application renders job descriptors in the MySQL database. The Queue Manager processes the job descriptors by creating job packages suitable for the underlying grid backend. These job packages are submitted by the Queue Manager into the grid backend. The grid backend processes the job packages and notifies the Queue Manager of any returning results. The Queue Manager notifies the submitter application in turn.

\section{Execution}
The Queue Manager is meant to be run as a daemon process. The sole, but mandatory argument taken by the Queue Manager is the name of the configuration file. The configuration file should be named {\tt qm.conf} and should be placed in the same directory in which the Queue Manager resides. The command below executes the Queue Manager as a daemon process and directing the log messages into the file {\tt CGManager.log}.
\begin{verbatim}
nohup ./CGManager bridge.conf 2>&1 > CGManager.log &
\end{verbatim}
Upon successful execution the Queue Manager can access the database and can initialize the grid backend. After initialization, the Queue Manager will poll the database for jobs to be processed in a varying interval between 1 second and 5 minutes.

The Queue Manager can also be deployed as a BOINC daemon. Refer to section \ref{subsec:boinc} on how to deploy the Queue Manager as a BOINC daemon. 

\section{Grid backends}
\subsection{BOINC}
The Queue Manager should be placed in a separate directory under the home directory of the corresponding BOINC project and should be executed by the project administrator user, to ensure that it has the proper right to access the BOINC database. In this case there is no need to create a separate database for the Queue Manager, but the tables for the Queue Manager can be inserted in the database of the BOINC project.

\subsection{EGEE}
The Queue Manager can be executed with the EGEE backend solely. In this case, you have to create a separate MySQL database with the neccessary tables supplied in the file {\tt schema.sql}. Refer to section \ref{sec:db} on how to create the tables. If the Queue Manager is to be executed with both backends at the same time, the EGEE backend can use the database of the BOINC project. 

\section{Database}
\label{sec:db}

The Queue Manager uses database tables to communicate with the job submitter. These tables has to be created prior to first use of the Queue Manager. A database has to be created for the tables of the Queue Manager or in case of the BOINC backend, the tables can be inserted in the database of the BOINC project. Locate the supplied file named {\tt schema.sql} or create it with the contents of section \ref{sec:schema} and execute the command below under the administrator user account of the grid environment, to create the neccessary tables for the Queue Manager.
\begin{verbatim}
mysql <database_name> < schema.sql
Assuming the database name is qm_db, eg.:
mysql qm_db < schema.sql
\end{verbatim}

\subsection{Adding algorithms to the database}

Prior to the first use of the Queue Manager the {\tt cg\_algqueue} table has to be populated with algrithms, so the Queue Manager will know which algorithms to handle. To insert a new algorithm into the {\tt cg\_algqueue} table execute the following command after configuring it to your needs:

\begin{verbatim}
INSERT INTO cg_algqueue (grid, alg, batchsize) VALUES 
(<NAME OF GRID>, <NAME OF EXECUTABLE>, <INT SIZE OF BATCH>);
\end{verbatim}

For example, let us assume that the Queue Manager will handle the following algorithm. The name of the algorithm is "Sample". The name of the executable for the algorithm is "sample\_executable". The name of the grid environment the algorithm will be executed in is "see-grid". The Queue Manager can pack up to 10 jobs in one package handled to the grid environment. The SQL command for the above example is as follows:

\begin{verbatim}
INSERT INTO cg_algqueue (grid, alg, batchsize) VALUES 
("see-grid", "sample_executable", 10);
\end{verbatim}

Note that the Queue Manager is capable of managing the same algorithm in multiple grid environments so the above example can be executed multiple times by changing the value of the grid name only.

\subsection{Removing algortihms from the database}

To remove an algorithm from the database provide the name of the grid and the name of the algorithm to   the following SQL command.

\begin{verbatim}
DELETE FROM cg_algqueue WHERE
grid = "see-grid" and alg =  "sample_executable";
\end{verbatim}


\subsection{Schema of the database}
\label{sec:schema}

\begin{verbatim}
/*
 * Schema description for CancerGrid job database
 */
drop table if exists cg_job;
drop table if exists cg_inputs;
drop table if exists cg_outputs;
drop table if exists cg_algqueue;

/*
 * Job table
 */
create table cg_job (
    id                  char(36)     not null,
    alg                 char(128)    not null,
    grid                varchar(254) not null,
    status              char(10)     not null,
    gridid              varchar(254),
    args                varchar(254),
    creation_time       timestamp    null default 
                                     current_timestamp,
    primary key (id)
) type=InnoDB;


/*
 * Job input table
 */
create table cg_inputs (
    id                  char(36)     not null,
    localname           varchar(254) not null,
    path                varchar(254) not null,
    primary key entry (id, localname),
    foreign key (id) references cg_job(id) on delete cascade
) type=InnoDB;

/*
 * Job output table
 */
create table cg_outputs (
    id                  char(36)     not null,
    localname           varchar(254) not null,
    path                varchar(254) not null,
    primary key entry (id, localname),
    foreign key (id) references cg_job(id) on delete cascade
) type=InnoDB;


/*
 * Algorithm queue table. Used for scheduling purposes
 */
create table cg_algqueue (
    grid                varchar(254) not null,
    alg                 char(128)    not null,
    batchsize           int          not null,
    statistics          text,
    primary key entry (grid, alg)
) type=InnoDB;
\end{verbatim}

\section{Configuration}

The Queue Manager needs to be properly configured before execution. For this a configuration file conforming with the format given below has to be provided. 

\begin{verbatim}
###############################################################
# Sample queue manager configuration file
#
# For the syntax, see the "Basic format of the file" and 
# "Possible value types" sections of the Desktop Entry 
# Specification at
# http://standards.freedesktop.org/desktop-entry-spec/latest/

############################
# Database access parameters
[database]

# Name of the database
name =

# Host name of the database
host =

# Database user
user =

# Database password
password =

# Max. number of database connections that can be 
# opened simultaneously
max-connections = 4

#####################################
# Sample grid using the DC-API plugin
[SZDG]

handler = DC-API
dc-api-config = dc-api.conf

###################################
# Sample grid using the EGEE plugin
[SEE-GRID]

handler = EGEE
wmproxy-endpoint = ...
myproxy_host = ...
myproxy_port = ...
myproxy_user = ...
myproxy_pass = ...

\end{verbatim}

The database access parameters are mandatory. {\tt host} is the name of the host running the database, usually {\tt localhost} (setting the value to 0 also means localhost). 

\subsection{Grid backend specific configuration}
\subsubsection{BOINC}
\label{subsec:boinc}
The Queue Manager uses the DC-API to communicate with the BOINC backend. The DC-API needs a separate configuration file. {\tt dc-api-config} parameter is the optional name of the DC-API configuration file. The default name of the file the Queue Manager looks for is {\tt dcapi.conf}. If you would like to place the DC-API configuration data in  another file, than you have to provied the {\tt dc-api-config} parameter. 

The format of the DC-API configuration file is as follows:

\begin{verbatim}
[Master]
#-----------------------------------------------------
# General configuration, for both BOINC implementation
#-----------------------------------------------------

#
# Working directory. boinc_appmgr will set it automatically
#

WorkingDirectory = NONE

#
# UUID Instance. boinc_appmgr will set it automatically
#

InstanceUUID = NONE

#
# Debugging level
#

LogLevel = Debug

#----------------------------------------------
# Configuration for BOINC DC-API implementation
#----------------------------------------------

#
# boinc config xml file. boinc_appmgr will set it automatically
#

BoincConfigXML = NONE

#
# BOINC project root directory. boinc_appmgr will set it 
# automatically
#

ProjectRootDir = NONE

#-------------------------
# Per-client configuration
#-------------------------

[Client-sample]

BatchHeadTemplate =
BatchBodyTemplate =
BatchTailTemplate =

BatchPackScript = batch_pack
BatchUnpackScript = batch_unpack
\end{verbatim}
The parameters of the DC-API configuration file can be set manually, or the Queue Manager can be deployed on the BOINC project with the \\ boinc\_appmgr utility, which also sets master side parameters and deploys the Queue Manager as a BOINC daemon. In this case the Queue Manager can be started and stopped along with the other BOINC daemons using the {\tt start} and {\tt stop} commands of BOINC respectively. 

\subsubsection{EGEE}

An optional configuration parameter for the EGEE backend is the \\ {\tt wmproxy-endpoint} parameter, which refers to the URL of the WMProxy. A myproxy can also be specified with the {\tt myproxy\_host, myproxy\_port, myproxy\_user, myproxy\_pass} parameters.

\end{document}