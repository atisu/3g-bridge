3G Bridge Metajob plugin: Submitting a batch of jobs to 3G Bridge
=================================================================

1. What is it?
--------------

The Metajob feature enables the users of the 3G Bridge to submit a batch of jobs
(a parameter study) in a single submission. There are (at least) two cases where
this feature can come in handy:

   i) When jobs are to be submitted to 3G Bridge through another middleware
     (gLite for example). Using the Metajob feature, thousands of jobs can be
      submitted at once to avoid the overhead of the middleware.

      A single job is submitted (1) through gLite. The batch is unfolded only in
      the 3G Bridge, then sub-jobs (*) are submitted to the destination grid
      individually:

	  User -(1)-> gLite -(1)-> 3GBridge =(*)=> [WorkerNodes]

  ii) As the status information of the sub-jobs are gathered and processed by
      the Metajob plugin internally, the user doesn't have to poll thousands of
      her jobs individually.

2. Glossary
-----------

meta-job:
	A meta-job is a job submitted to 3G Bridge with a special extra input
	file containing job definitions. The name of the file must start with
	_3gb-metajob (this identifies a meta-job). In this document, we will
	always refer to this file as the "_3gb-metajob file" although its name
	can be suffixed with anything. When submitting a meta-job, only one
	_3gb-metajob file can be specified.

_3gb-metajob file:
	The file containing job definitions and directives for
	batch-execution. This file is supplied as an extra input file and
	interpreted by the 3G Bridge.

sub-job:
	Job generated by 3G Bridge from a meta-job.

Input ports:
        When a job is submitted, inputs are specified with
	(logical file name, url) pairs (optionally an md5 hash and size can be
        specified with the url). In this document, we refer to the set of
        distinct logical file names as _input ports_ of a job.
	(See example in 4.1, and the explanation after it.)

3. Requirements
---------------

  o The Metajob feature is a built-in feature, there are no extra requirements.

  It is assumed that the reader knows and understands ordinary job-submission
  using wsclient.

4. How to use it?
-----------------

  4.1 Restrictions
  ----------------

  The Metajob feature supports parameter studies only. That is, only the
  arguments and sources of the input files can vary among sub-jobs. The
  executable, the destination grid, the output files' names and the input ports
  (as defined by the logical names of specified inputs) are fixed.

  In the following example of a meta-job submission <<.>> marks variable
  parameters. Everything else will be inherited by sub-jobs.

  <example>
  wsclient -m add -e http://3gb-host.org:8091                          \
	   -n algName -g DestGrid                                      \
	   -o 'output.txt'                                             \
	   -a '<< default args >>'                                     \
	   -i 'input1.txt=<< Url for input file >>'                    \
	   -i 'input2.txt=<< Url=MD5hash=size for input file >>'       \
	   -i '_3gb-metajob=Url_for_3gb_metajob_file'
  </example>

  Notice that in the input specifications, only the URLs are marked with <<.>>
  The set of input ports (here: { input1.txt, input2.txt }) is fixed. All
  sub-jobs will have the same input files, only with different source URLs (and
  optionally an MD5 hash and size -- see wsclient help).

  As the meta-job plugin has no access to the user's machine, specifying local
  files for the sub-jobs as inputs is impossible. Therefore, all input files
  must be specified as a remote file - with a URL. This means that before
  submitting the meta-job, all input files referenced in the _3gb-metajob file
  must be made available on a server through the specified URL-s. This generally
  means http, but specific plugins can support other protocols. The _3gb-metajob
  file required to be available through http as the Metajob plugin doesn't
  support any other protocols. For further information on specifying remote
  files for a 3G Bridge job, see the 3G Bridge documentation.

  The Metajob feature assumes that all sub-jobs generate the same output files.

  4.2 The _3gb-metajob file
  -------------------------

  The _3gb-metajob file contains the definitions of sub-jobs in a procedural
  form:

    # Example _3gb-metajob file

    %Required 80%
    %SuccessAt 60%

    %Comment 22_1_1
    Arguments = -f 22
    Input = input1.txt=http://url.for/input1_1.txt
    Input = input2.txt=http://url.for/input2_1.txt
    Queue 2

    %Comment 22_1_2
    Arguments = -f 22
    Input = input2.txt=http://url.for/input2_1.txt
    Queue

    %Comment 444_1_2
    Arguments = -f 444
    Queue

  The meta-job definition language is case sensitive.

  Each line contains a single instruction, instructions cannot be split in
  multiple lines. An instruction starting with a % is called a directive. (They
  are emphasized because they are handled specially.)

  Full-line comments begin with a '#'.
  WARNING! There are only full-line comments. For example the instruction
    Argument = -f 22 # 33
  will set the Argument to '-f 22 # 33' instead of '-f 22'.

  Furthermore, quotes are not treated specially. They will be included in the
  argument string or the URL-s as they are.

  4.3 Specifying sub-jobs
  -----------------------

  Jobs have the following attributes:
       a) algorithm, destination grid, outputs
       b) list of logical input file names
       c) for each input file, a url
       d) arguments

  These define a template for sub-jobs.

  For every sub-job, a) and b) is the same. These fixed parameters are specified
  by the wsclient call.

  Arguments and source URLs for the input files are specified the following way:
   i) They get default values from the wsclient call.
  ii) Values can be changed by instructions in the _3gb-metajob file:
      - Arguments = *
	    will set the arguments to *, where * is the string between the '='
	    and the end-of-line.
      - Input = logicalName=URL
	    will set the source URL for the input port 'logicalName' to the
	    given URL. The logical name must be in the fixed set b).

  Whenever a Queue instruction is issued, a sub-job is instantiated from the
  current state of the template. A Queue N instruction will create N identical
  sub-jobs. This multi-submission can be used for submitting randomized
  simulations (e.g. monte carlo) or to ensure that at least a single instance of
  a sub-job will complete successfully (if jobs seem to fail frequently).

  See example in 4.2

  4.4 Letting the 3G Bridge to poll sub-jobs
  ------------------------------------------

  Polling each sub-job individually with wsclient is cumbersome and
  inefficient. The %Required and %SuccessAt directives can be used to control
  how 3G Bridge interprets sub-job statuses. The meta-job's status will be set
  accordingly, so the user will only have to poll the meta-job.

  %Required tells the 3G Bridge how many sub-jobs are needed at least for the
   meta-job to be successful. If too many sub-jobs have failed, the meta-job
   will fail too.

  %SuccessAt tells the 3G Bridge how many sub-jobs are needed at most for the
   meta-job to be successful. If this many sub-jobs finish successfully, all
   remaining (failed, running, not submitted) sub-jobs are canceled and deleted
   as they are considered unneeded.

  Both directives can be specified as an exact number or as a percentage.

  They are optional, the default value for both is 100%.

  4.5 Identifying sub-jobs
  ------------------------

  All jobs - sub-jobs too - are identified with UUID-s in the 3G Bridge. In the
  _3gb-metajob file, a %Comment directive specifies a user-comment on a set of
  parameters. After generating a sub-job, the 3G Bridge assigns this comment to
  the generated sub-job's unique identifier. The only purpose of this is to
  enable the user to identify sub-jobs: which unique id belongs to which set of
  parameters.

  This instruction is a directive, because its value is not stored like, for
  example the Argument instruction: after the next Queue command, the %Comment
  will be reset:

       %Required 33%
       %SuccessAt 66%

       %Comment job_with_arg_22
       Arguments = 22
       Input = input1.txt=url_for_input1
       Queue 2

       # Here, %Comment is ''; it must be explicitly set for each parameter set
       #                       to avoid confusion
       Arguments = 33
       Queue

  After sub-jobs has been generated, a mapping file is created by the 3G
  Bridge. This file is a valid _3gb-metajob file, semantically equivalent to the
  one the user submitted. The difference is that each generated sub-job has a
  full, explicit definition (before each Queue, all inputs and arguments are set
  explicitly), %Required and %SuccessAt is converted to specific numbers, and
  each sub-job is annotated with its 3G Bridge identifier. The example above
  will result in the following mapping:

       %Comment job_with_arg_22
       %JobId subjob-uuid-1
       Arguments = 22
       Input = input1.txt=url_for_input1
       Queue

       %Comment job_with_arg_22
       %JobId subjob-uuid-2
       Arguments = 22
       Input = input1.txt=url_for_input1
       Queue

       %Comment
       %JobId subjob-uuid-3
       Arguments = 33
       Input = input1.txt=url_for_input1
       Queue

       %Required 1
       %SuccessAt 2
       # Total generated: 3

  This mapping can be submitted back to 3G Bridge with the same effect as the
  original. %JobId directives are valid, they're simply omitted.

  If the user provides useful %Comments for her jobs, she can search through
  them to find a specific parameter set. The unique job id of the sub-job which
  used that given parameter set is given after the %Comment directive.

  4.6 Getting the output of sub-jobs
  ----------------------------------

  A meta-job will produce the same output files as any of its sub-jobs (for
  compatibility reasons: the existing infrastructure doesn't have to be
  modified). But actually, the output files of a meta-job are archives
  containing corresponding outputs of sub-jobs. In these archives files are
  arranged in directories so the user can find which sub-job produced a given
  output file. (Indirectly: which *parameter set* produced a given file -- see:
  Identifying sub-jobs.)

  The directory structure is generated from the unique identifiers of the
  sub-jobs. To avoid clutter, the directories are separated by the first two
  letters of their names.

  Example: A meta-job is defined to have two output ports: out1.txt and
  out2.txt. This means that each and every sub-job will produce those files and
  also, the meta-job will produce files called exactly out1.txt and
  out2.txt. The result files will have an internal structure something like the
  following:

  out1.txt // actually: tar.gz
  +--d6/
  |  +--d6be9f05-003a-4cdb-be1e-0b8cbb1fbdb5/
  |     +--out1.txt
  ...
  +--c0/
  |  +--c0ec606a-d706-45e3-bc4a-66228b6b2987/
  |     +--out1.txt
  +--metajobUUID-mapping.txt
	
  out2.txt // actually: tar.gz
  +--d6/
  |  +--d6be9f05-003a-4cdb-be1e-0b8cbb1fbdb5/
  |     +--out2.txt
  ...
  +--c0/
  |  +--c0ec606a-d706-45e3-bc4a-66228b6b2987/
  |     +--out2.txt
  +--metajobUUID-mapping.txt

  All *-mapping.txt files are the same. These files can be used to identify
  which sub-job generated a particular output. The content of this file is
  described in the next section.
  
  Merging the output is easy:

    cd directory/where/I/want/my/output/to/be/merged
    tar xzf path_to_archives/out1.txt
    tar xzf path_to_archives/out2.txt

  The result will be:

  ./
  +--d6/
  |  +--d6be9f05-003a-4cdb-be1e-0b8cbb1fbdb5/
  |     +--out1.txt
  |     +--out2.txt
  ...
  +--c0/
  |  +--c0ec606a-d706-45e3-bc4a-66228b6b2987/
  |     +--out1.txt
  |     +--out2.txt
  +--metajobUUID-mapping.txt

  4.7 Using the Metajob feature through gLite
  --------------------------------------------

5. Using gLite for submission
-----------------------------

The Metajob feature can be used through gLite as well. In the JDL, the user must
specify the _3gb-metajob file as an input file.

In this case, the _3gb-metajob file will be submitted as a sandbox input file,
and thus can reside on the user's file system. (Cf. 4.1, where the _3gb-metajob
file was required to be available through an http URL. In this case, the mCE
will take care of this.) All other input files must still be made available
remotely (see 4.1).

<example JDL>
Executable	= "dsp";
Arguments	= "<< Default arguments >>";
InputSandbox	= {
			"gsiftp://exe.url/dsp",
		  	"input1.txt",
			"input2.txt",
			"_3gb-metajob"
		};
OutputSandbox	= {"output.txt"};
</example>

For futher information, see 

6. Configuring the Metajob plugin
---------------------------------

See the man page 3g-bridge.conf(5) for information.